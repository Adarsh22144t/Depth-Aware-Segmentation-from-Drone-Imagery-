{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/pytorch-msssim/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pytorch-msssim\n",
      "  Downloading pytorch_msssim-1.0.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.11/site-packages (from pytorch-msssim) (2.2.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch->pytorch-msssim) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from torch->pytorch-msssim) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/lib/python3.11/site-packages (from torch->pytorch-msssim) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (from torch->pytorch-msssim) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch->pytorch-msssim) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.11/site-packages (from torch->pytorch-msssim) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch->pytorch-msssim) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/anaconda3/lib/python3.11/site-packages (from sympy->torch->pytorch-msssim) (1.3.0)\n",
      "Downloading pytorch_msssim-1.0.0-py3-none-any.whl (7.7 kB)\n",
      "Installing collected packages: pytorch-msssim\n",
      "Successfully installed pytorch-msssim-1.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pytorch-msssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100:   0%|          | 0/750 [00:00<?, ?batch/s]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "train_unet_denoiser.py\n",
    "\n",
    "End-to-end training script for a U-Net denoising autoencoder with PSNR + SSIM metrics.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pytorch_msssim import ssim  # <-- NEW\n",
    "\n",
    "# ----------------------------\n",
    "# User settings (edit these)\n",
    "# ----------------------------\n",
    "TRAIN_DIR = \"/Users/sadik2/main_project/train\"  # <- set this to the parent 'train' folder\n",
    "BATCH_SIZE = 2\n",
    "NUM_WORKERS = 0\n",
    "LR = 1e-4\n",
    "NUM_EPOCHS = 100\n",
    "CHECKPOINT_DIR = \"./checkpoints\"\n",
    "CHECKPOINT_FREQ_EPOCHS = 1\n",
    "RESUME_CHECKPOINT = None\n",
    "NOISE_STD = 0.08\n",
    "IMAGE_SIZE = (1280, 720)  # width, height\n",
    "SEED = 42\n",
    "SAVE_METRICS_CSV = \"metrics.csv\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# ----------------------------\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Collect all .png images\n",
    "# ----------------------------\n",
    "def collect_image_paths(train_dir):\n",
    "    train_dir = Path(train_dir)\n",
    "    image_paths = []\n",
    "    for top in [\"neighbourhood\", \"park\"]:\n",
    "        base = train_dir / top\n",
    "        if not base.exists():\n",
    "            continue\n",
    "        for img_dir in base.rglob(\"image\"):\n",
    "            for ext in (\"*.png\", \"*.PNG\"):\n",
    "                for p in img_dir.glob(ext):\n",
    "                    image_paths.append(str(p.resolve()))\n",
    "    return sorted(set(image_paths))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Dataset\n",
    "# ----------------------------\n",
    "class DenoiseDataset(Dataset):\n",
    "    def __init__(self, image_paths, image_size=(1280, 720), noise_std=0.08, transforms_aug=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.noise_std = noise_std\n",
    "        self.w, self.h = image_size\n",
    "        self.to_tensor = transforms.Compose([\n",
    "            transforms.Resize((self.h, self.w)),  # torchvision expects (H, W)\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        self.aug = transforms_aug\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        p = self.image_paths[idx]\n",
    "        img = Image.open(p).convert(\"RGB\")\n",
    "        if self.aug:\n",
    "            img = self.aug(img)\n",
    "        clean = self.to_tensor(img)\n",
    "        noise = torch.randn_like(clean) * self.noise_std\n",
    "        noisy = torch.clamp(clean + noise, 0.0, 1.0)\n",
    "        return noisy, clean, p\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# U-Net model\n",
    "# ----------------------------\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=3, features=(64, 128, 256, 512)):\n",
    "        super().__init__()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.ups = nn.ModuleList()\n",
    "        for f in features:\n",
    "            self.downs.append(DoubleConv(in_channels, f))\n",
    "            in_channels = f\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1] * 2)\n",
    "        rev_features = features[::-1]\n",
    "        up_in = features[-1] * 2\n",
    "        for f in rev_features:\n",
    "            self.ups.append(nn.ConvTranspose2d(up_in, f, 2, stride=2))\n",
    "            self.ups.append(DoubleConv(up_in, f))\n",
    "            up_in = f\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        out = x\n",
    "        for down in self.downs:\n",
    "            out = down(out)\n",
    "            skip_connections.append(out)\n",
    "            out = self.pool(out)\n",
    "        out = self.bottleneck(out)\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        up_idx = 0\n",
    "        for i in range(0, len(self.ups), 2):\n",
    "            trans = self.ups[i]\n",
    "            double = self.ups[i + 1]\n",
    "            out = trans(out)\n",
    "            skip = skip_connections[up_idx]\n",
    "            up_idx += 1\n",
    "            if skip.shape[2:] != out.shape[2:]:\n",
    "                h_min = (skip.shape[2] - out.shape[2]) // 2\n",
    "                w_min = (skip.shape[3] - out.shape[3]) // 2\n",
    "                skip = skip[:, :, h_min:h_min + out.shape[2], w_min:w_min + out.shape[3]]\n",
    "            out = torch.cat([skip, out], dim=1)\n",
    "            out = double(out)\n",
    "        return torch.sigmoid(self.final_conv(out))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Metrics\n",
    "# ----------------------------\n",
    "def mse_loss(pred, target):\n",
    "    return nn.functional.mse_loss(pred, target)\n",
    "\n",
    "\n",
    "def psnr(pred, target, max_val=1.0):\n",
    "    mse = torch.mean((pred - target) ** 2).item()\n",
    "    if mse == 0:\n",
    "        return float(\"inf\")\n",
    "    return 10 * math.log10((max_val ** 2) / mse)\n",
    "\n",
    "\n",
    "def ssim_metric(pred, target):\n",
    "    # expects tensors in [0,1]\n",
    "    return ssim(pred, target, data_range=1.0, size_average=True).item()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Checkpoint utils\n",
    "# ----------------------------\n",
    "def save_checkpoint(state, checkpoint_dir, epoch):\n",
    "    filename = os.path.join(checkpoint_dir, f\"checkpoint_epoch{epoch}.pth\")\n",
    "    torch.save(state, filename)\n",
    "    latest = os.path.join(checkpoint_dir, \"latest_checkpoint.pth\")\n",
    "    torch.save(state, latest)\n",
    "    print(f\"[checkpoint] saved: {filename}\")\n",
    "\n",
    "\n",
    "def load_checkpoint(path, model, optimizer=None, device=DEVICE):\n",
    "    print(f\"[checkpoint] Loading checkpoint: {path}\")\n",
    "    checkpoint = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model_state\"])\n",
    "    if optimizer is not None and \"optimizer_state\" in checkpoint:\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "    start_epoch = checkpoint.get(\"epoch\", 0) + 1\n",
    "    return start_epoch\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Training loop\n",
    "# ----------------------------\n",
    "def train():\n",
    "    image_paths = collect_image_paths(TRAIN_DIR)\n",
    "    if len(image_paths) == 0:\n",
    "        raise RuntimeError(f\"No images found under {TRAIN_DIR}.\")\n",
    "    print(f\"Found {len(image_paths)} images.\")\n",
    "\n",
    "    dataset = DenoiseDataset(image_paths, image_size=IMAGE_SIZE, noise_std=NOISE_STD)\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True)\n",
    "\n",
    "    model = UNet(in_channels=3, out_channels=3).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "    start_epoch = 1\n",
    "    if RESUME_CHECKPOINT and os.path.exists(RESUME_CHECKPOINT):\n",
    "        start_epoch = load_checkpoint(RESUME_CHECKPOINT, model, optimizer, DEVICE)\n",
    "        print(f\"Resuming from epoch {start_epoch}\")\n",
    "\n",
    "    metrics_path = os.path.join(CHECKPOINT_DIR, SAVE_METRICS_CSV)\n",
    "    if not os.path.exists(metrics_path):\n",
    "        with open(metrics_path, \"w\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"timestamp\", \"epoch\", \"train_loss\", \"avg_psnr\", \"avg_ssim\"])\n",
    "\n",
    "    for epoch in range(start_epoch, NUM_EPOCHS + 1):\n",
    "        model.train()\n",
    "        epoch_loss, epoch_psnr, epoch_ssim = 0.0, 0.0, 0.0\n",
    "        n_batches = 0\n",
    "\n",
    "        pbar = tqdm(loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS}\", unit=\"batch\")\n",
    "        for noisy, clean, _ in pbar:\n",
    "            noisy, clean = noisy.to(DEVICE), clean.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(noisy)\n",
    "            loss = mse_loss(out, clean)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "            b_loss = loss.item()\n",
    "            b_psnr = psnr(out.detach().cpu(), clean.detach().cpu())\n",
    "            b_ssim = ssim_metric(out, clean)\n",
    "\n",
    "            epoch_loss += b_loss\n",
    "            epoch_psnr += b_psnr\n",
    "            epoch_ssim += b_ssim\n",
    "            n_batches += 1\n",
    "            pbar.set_postfix({\"loss\": f\"{b_loss:.4f}\", \"psnr\": f\"{b_psnr:.2f}\", \"ssim\": f\"{b_ssim:.4f}\"})\n",
    "\n",
    "        avg_loss = epoch_loss / n_batches\n",
    "        avg_psnr = epoch_psnr / n_batches\n",
    "        avg_ssim = epoch_ssim / n_batches\n",
    "        print(f\"[epoch {epoch}] loss={avg_loss:.6f}, psnr={avg_psnr:.2f}, ssim={avg_ssim:.4f}\")\n",
    "\n",
    "        scheduler.step(avg_loss)\n",
    "\n",
    "        with open(metrics_path, \"a\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([datetime.utcnow().isoformat(), epoch, f\"{avg_loss:.6f}\", f\"{avg_psnr:.4f}\", f\"{avg_ssim:.4f}\"])\n",
    "\n",
    "        if epoch % CHECKPOINT_FREQ_EPOCHS == 0 or epoch == NUM_EPOCHS:\n",
    "            state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state\": model.state_dict(),\n",
    "                \"optimizer_state\": optimizer.state_dict(),\n",
    "                \"config\": {\"train_dir\": TRAIN_DIR, \"image_size\": IMAGE_SIZE, \"noise_std\": NOISE_STD},\n",
    "            }\n",
    "            save_checkpoint(state, CHECKPOINT_DIR, epoch)\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
